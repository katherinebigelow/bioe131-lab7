{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7\n",
    "## Part 1\n",
    "Using np.random.choice, generate 100 megabytes(8 bits/byte* 1024 bytes/kilobyte* 1024 kilobytes/megabyte* 100) of random data containing 100%, 90%, 80%, 70%, 60%, and 50% zeros. Be sure to call np.packbits on your data before writing it to a file. For example:\n",
    "\n",
    "`myvar= np.random.choice([0, 1], size=1024, replace=True, p=[0.5, 0.5])\n",
    "myvar = np.packbits(myvar)`\n",
    "\n",
    "Then write this data to a file in your home directory, like this:\n",
    "\n",
    "`open(“zeros_100p”, “wb”).write(zeros_100p)`\n",
    "\n",
    "Next, generate DNA and protein sequences 100 million letters long and write those to your home directory.The probability of each letter should be equal.To write stringsgenerated in Numpy to a file, you’ll have to use a slightly different command, like this:\n",
    "\n",
    "`open(“nt_seq.fa”, “w”).write(“”.join(my_nt_seq))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [1.00, .90, .80, .70, .60, .50]:\n",
    "    myvar = np.random.choice([0, 1], size=1024, replace=True, p=[i, 1-i])\n",
    "    myvar = np.packbits(myvar)\n",
    "    name = \"zeros_\" + str(int(100*i)) + \"p\"\n",
    "    open(name, \"xb\").write(myvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nt_seq = np.random.choice([\"A\", \"T\", \"C\", \"G\"], size = int(1e8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = open(\"nt_seq.fa\", \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for nucleotide in nt_seq:\n",
    "    fd.write(nucleotide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\".join on a long array is a very expensive operation that crashes my computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amino_acids = [\"A\", \"R\", \"N\", \"D\", \"B\", \"C\", \"E\"]\n",
    "amino_acids += [\"Q\", \"Z\", \"G\", \"H\", \"I\", \"L\", \"K\"]\n",
    "amino_acids += [\"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_seq = np.random.choice(amino_acids, size = int(1e8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = open(\"pt_seq\", \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for aa in pt_seq:\n",
    "    fd.write(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "On each of the files you generated above, run gzip, bzip, pbzip2and ArithmeticCompress as follows:\n",
    "\n",
    "`time gzip –k zeros_100p\n",
    "time bzip2 –k zeros_100p\n",
    "time pbzip2 –k zeros_100p\n",
    "time ArithmeticCompress zeros_100p zeros_100p.art`\n",
    "\n",
    "I ran these commands for each of the files, with the following outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos = [\"gzip\", \"bzip2\", \"pbzip2\", \"Arithmetic Compress\"]\n",
    "zeros_100p_times = [0.002, 0.002, 0.005, 0.005]\n",
    "zeros_90p_times =  [0.003, 0.002, 0.005, 0.005]\n",
    "zeros_80p_times =  [0.002, 0.002, 0.005, 0.005]\n",
    "zeros_70p_times =  [0.002, 0.003, 0.005, 0.005]\n",
    "zeros_60p_times =  [0.002, 0.002, 0.005, 0.005]\n",
    "zeros_50p_times =  [0.002, 0.002, 0.005, 0.005]\n",
    "\n",
    "types = [\"original\", \".gz\", \".bz2\", \".art\"]\n",
    "zeros_100p_sizes = [128, 35, 39, 1100]\n",
    "zeros_90p_sizes =  [128, 130, 131, 1100]\n",
    "zeros_80p_sizes =  [128, 158, 175, 1100]\n",
    "zeros_70p_sizes =  [128, 161, 204, 1100]\n",
    "zeros_60p_sizes =  [128, 161, 207, 1200]\n",
    "zeros_50p_sizes =  [128, 161, 207, 1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nt_times = [12.179, 9.468, 0.666, 21.245]\n",
    "pt_times = [4.163, 10.088, 0.802, 28.862]\n",
    "\n",
    "nt_sizes = [\"96M\", \"28M\", \"27M\", \"24M\"]\n",
    "pt_sizes = [\"96M\", \"59M\", \"55M\", \"54M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Which algorithm achieves the best level of compression on each file type?\n",
    "* gzip works well on the small file that was all zeroes, but for the mainly random small files the original was the smallest.\n",
    "* Arithmetic compress was the fastest for the larger nt and pt files.\n",
    "\n",
    "Which algorithm is the fastest? \n",
    "* pbzip2 was the fastest for larger files, but its overhead made it slower for smaller files (making gzip or bzip2 faster).\n",
    "* Arithmetic compress was the slowest by far for larger files, but compressed way more.\n",
    "\n",
    "What is the difference between bzip2 and pbzip2? Do you expect one to be faster and why? \n",
    "* pbzip2 is a multi-threaded version of bzip2, so on a cpu that supports multithreading, it should be faster than bzip2.\n",
    "* However, for smaller files, the multithreading doesn't really do much but add overhead to the runtime.\n",
    "\n",
    "How does the level of compression change as the percentage of zeros increases? Why does this happen?\n",
    "* As the percentage of zeros increases, the files are able to be compressed more, as the amount of entropy in these files is lower.\n",
    "\n",
    "What is the minimum number of bits required to store a single DNA base?\n",
    "* In a fully random sequence, it would be log2(4) = 2 bits\n",
    "* However, one base could potentially be encoded with one bit (eg the highest-frequency character after Huffman encoding).\n",
    "\n",
    "What is the minimum number of bits required to store an amino acid letter?\n",
    "* Similarly to the previous answer, it would range between one bit and log2(20ish) = 5 bits\n",
    "\n",
    "In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?\n",
    "* in number of bytes:\n",
    "  * 27348411        nt_seq.fa.bz2\n",
    "  * 29223170        nt_seq.fa.gz\n",
    "  * 56997478        pt_seq.bz2\n",
    "  * 61755205        pt_seq.gz\n",
    "\n",
    "Are gzip and bzip2 performing well on DNA and proteins?\n",
    "* Somewhat, if only because they get to represent the file from being in character/string format to just representing like 4 nucleotides or 20ish amino acids\n",
    "\n",
    "## Part 3\n",
    "Using what you’ve learned about querying biological databases, find the nucleic acid sequences of gp120 homologs from at least 10 different HIV isolates and concatenate them together into a single multi-FASTA.\n",
    "\n",
    "A priori, do you expect to achieve better or worse compression here than random data? Why?\n",
    "* I expect to achieve better compression here, as the sequence isn't random and thus has lower entropy (ie compression algos can take advantages of the patters which appear in these sequences)\n",
    "\n",
    "Now, compress the multi-FASTA using gzip, bzip2, and arithmetic coding. How does the compression ratio of this file compare to random data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "You’re working at a biotech company thatgenerates 1000 terabytes of data every day. In a meeting, your boss mentions that it costs the company \\$50 per terabyte of hard disk space, and so every 1% reduction in data that must be stored translates into a \\$500 savings per day.Your team will get a bonus this year equal to the amount of savings you’re able to generate by compressing the company’s data.\n",
    "\n",
    "Let’s make some assumptions about the contents of the data at your biotech company. Most of the data, say 80%, is re-sequencing of genomes and plasmids that are very similar to each other. Another 10% might be protein sequences, and the last 10% are binary microscope images which we’ll assume follow the worst-case scenario of being completely random. \n",
    "\n",
    "Given the benchmarking data you obtained in this lab, which algorithm do you propose to use for each type of data? Provide an estimate for the fraction of space you can save using your compression scheme. How much of a bonus do you anticipate receiving this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compression_ratio = .8*1 # part 3\n",
    "compression_ratio += 0.1*1 # part 1 for amino acids\n",
    "compression_ratio += 0.1*1 # part 1 for random files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonus amount: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Bonus amount:\", (1-compression_ratio)*1000*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
